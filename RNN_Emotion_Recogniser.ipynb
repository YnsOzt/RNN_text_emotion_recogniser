{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Emotion_Recogniser.pynb",
      "provenance": [],
      "collapsed_sections": [
        "eOt5TL3j8dEV",
        "PVesaIQc98rW",
        "mtQtl3yZ8gQJ",
        "1D_rSkTJdDLP",
        "BOYH6O4Ji9Hg",
        "t1V1DxHBVcJ7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOt5TL3j8dEV",
        "colab_type": "text"
      },
      "source": [
        "# Move to the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNN4QiD48Q80",
        "colab_type": "code",
        "outputId": "783d6a7d-cc50-4150-b4e5-c54c98737171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd ./drive/My\\ Drive/perso/Emotion_recognition_over_txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/perso/Emotion_recognition_over_txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVesaIQc98rW",
        "colab_type": "text"
      },
      "source": [
        "# Import all the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs12UTsl-F6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtQtl3yZ8gQJ",
        "colab_type": "text"
      },
      "source": [
        "# Fetch and visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PeAppDTDn_2",
        "colab_type": "text"
      },
      "source": [
        "convert data in CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK-TkRrO_KUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('emotion.csv', 'w') as f1:\n",
        "    writer = csv.writer(f1)\n",
        "    writer.writerow([\"id\", \"x\", \"y\"]) #headers\n",
        "    with open(\"./emotion.data\", \"r\", newline='') as f2:\n",
        "      for s in f2:\n",
        "        sentence = s.split(\",\")\n",
        "        writer.writerow([sentence[0], sentence[1], sentence[2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDtNf-9s8H3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_prepocessing = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "Y_prepocessing = data.LabelField(dtype = torch.float,batch_first=True)\n",
        "\n",
        "fields = [(None, None), ('x',X_prepocessing),('y', Y_prepocessing)]\n",
        "\n",
        "#loading custom dataset\n",
        "all_data = data.TabularDataset(path = 'emotion.csv',format = 'csv',fields = fields,skip_header = True)\n",
        "all_data.examples = all_data.examples[1::]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w48IJSHpD1UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print preprocessed text\n",
        "train_data, test_data, val_data = all_data.split(split_ratio=[0.90, 0.02, 0.08], random_state = random.seed(31))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW-YF4BwIVbF",
        "colab_type": "code",
        "outputId": "a58e8d88-a5a4-42af-8c17-05391080be1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Training set size {}\".format(len(train_data)))\n",
        "print(\"Test set size {}\".format(len(test_data)))\n",
        "print(\"Validation set size {}\".format(len(val_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size 375128\n",
            "Test set size 33345\n",
            "Validation set size 8336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfLOHJt1rp3p",
        "colab_type": "code",
        "outputId": "d52341a2-d1c2-492a-8db9-0cecd477bffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "train_data_spread = {}\n",
        "for data in train_data : \n",
        "  if data.y in train_data_spread:\n",
        "    train_data_spread[data.y] += 1\n",
        "  else:\n",
        "    train_data_spread[data.y] = 1\n",
        "\n",
        "test_data_spread = {}\n",
        "for data in test_data : \n",
        "  if data.y in test_data_spread:\n",
        "    test_data_spread[data.y] += 1\n",
        "  else:\n",
        "    test_data_spread[data.y] = 1\n",
        "\n",
        "val_data_spread = {}\n",
        "for data in val_data : \n",
        "  if data.y in val_data_spread:\n",
        "    val_data_spread[data.y] += 1\n",
        "  else:\n",
        "    val_data_spread[data.y] = 1\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 7))\n",
        "axes[0].set_title('Training set')\n",
        "for item in train_data_spread.keys():\n",
        "  axes[0].bar(item, train_data_spread[item])\n",
        "axes[1].set_title('Test set')\n",
        "for item in test_data_spread.keys():\n",
        "  axes[1].bar(item, test_data_spread[item])\n",
        "axes[2].set_title('Val set')\n",
        "for item in val_data_spread.keys():\n",
        "  axes[2].bar(item, val_data_spread[item])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJcAAAGrCAYAAAB9iXaZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlVzReXzMzMzMzMzMysav8HXP/15G8ugvwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgHHnf3RvqFP",
        "colab_type": "text"
      },
      "source": [
        "We can see that our dataset is not balanced at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAFz3lQkQSQg",
        "colab_type": "text"
      },
      "source": [
        "Build the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vKx-pQtLuPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize glove embeddings\n",
        "X_prepocessing.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\") # using pretrained embedding\n",
        "Y_prepocessing.build_vocab(train_data)\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of X_prepocessing vocabulary:\",len(X_prepocessing.vocab))\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of Y_prepocessing vocabulary:\",len(Y_prepocessing.vocab))\n",
        "#Commonly used words\n",
        "print(X_prepocessing.vocab.freqs.most_common(10))  \n",
        "#Word dictionary\n",
        "print(X_prepocessing.vocab.stoi)   #string to identifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq7g0fTvREb-",
        "colab_type": "code",
        "outputId": "f72d8f82-98a3-44a2-ee6b-e56a2aa72165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "print(\"Using {}\".format(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgGWTbYyQ_lT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator for train, test, val\n",
        "train_iterator = data.BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda item: len(item.x),\n",
        "    sort_within_batch=True,\n",
        "    device = device)\n",
        "\n",
        "test_iterator = data.BucketIterator(\n",
        "    test_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda item: len(item.x),\n",
        "    sort_within_batch=True,\n",
        "    device = device)\n",
        "\n",
        "val_iterator = data.BucketIterator(\n",
        "    val_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda item: len(item.x),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D_rSkTJdDLP",
        "colab_type": "text"
      },
      "source": [
        "# Defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOQR0dZNdGVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim, hidden_state, nb_layers, nb_class, padding_idx, bidirectional=True):\n",
        "    super(Net, self).__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
        "\n",
        "    self.lstm = nn.LSTM(emb_dim, hidden_state, nb_layers, batch_first=True, bidirectional=True)\n",
        "    \n",
        "    self.fc1 = nn.Linear(hidden_state * 2, nb_class)\n",
        "    \n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x)\n",
        "\n",
        "    output, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "    h_n = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim = 1)\n",
        "    \n",
        "    x = self.fc1(h_n)\n",
        "\n",
        "    return self.softmax(x) #output ==> (BS, max_nb_word, nb_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOYH6O4Ji9Hg",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDNgxzbGkcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS_DIR = \"models\"\n",
        "MODEL_NAME = \"best_model.pth\"\n",
        "def save_model(model, directory=MODELS_DIR, model_name=MODEL_NAME):\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "  if \".pth\" not in model_name:\n",
        "    model_name += \".pth\"\n",
        "  print(\"Saving model\")\n",
        "  torch.save(model.state_dict(), os.path.join(directory, model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOiyBQvtha_f",
        "colab_type": "code",
        "outputId": "89c662dc-35d4-4a0b-cc9f-14a592da8b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#GLOBAL PARAM\n",
        "LOSS = 'loss'\n",
        "EVAL_PRECISION = 'eval_precision'\n",
        "\n",
        "#Training parameters\n",
        "num_epochs = 50\n",
        "early_stopping_rate = 5\n",
        "patience = early_stopping_rate\n",
        "early_stopping_param = LOSS # loss || eval_precision\n",
        "lr_decay_patience = 2\n",
        "assert early_stopping_param == LOSS or early_stopping_param == EVAL_PRECISION, \"early stopping parameter is not correct, you have to chose it between loss or eval_precision\"\n",
        "\n",
        "#Neural net parameters\n",
        "vocab_size = len(X_prepocessing.vocab)\n",
        "nb_class = len(Y_prepocessing.vocab)\n",
        "emb_dim = 200\n",
        "hidden_state = 320\n",
        "nb_layers = 1\n",
        "bidirectional = True\n",
        "padding_idx = X_prepocessing.vocab.stoi['<pad>'] #get the index of padding in the vocabulary\n",
        "\n",
        "model = Net(vocab_size, emb_dim, hidden_state, nb_layers, nb_class, padding_idx,bidirectional).to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (emb): Embedding(28992, 200, padding_idx=1)\n",
            "  (lstm): LSTM(200, 320, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=640, out_features=6, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Zalc4Ri3C5",
        "colab_type": "code",
        "outputId": "5dd5424d-ef77-4fc0-96b6-05028937c0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "#learning rate optimizer ==> https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min' if early_stopping_param == LOSS else 'max', patience=lr_decay_patience, verbose=True) \n",
        "\n",
        "best_early_stopping_param = 0 if early_stopping_param == EVAL_PRECISION else float(\"inf\")\n",
        "\n",
        "print(\"Start training :\")\n",
        "for epoch in range(50):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  batch_loss = 0\n",
        "  print(\"Starting epoch\", epoch+1)\n",
        "  for i, ((data, labels), _) in enumerate(train_iterator):\n",
        "    X = data[0].to(device)\n",
        "    y = labels.to(device)\n",
        "    txt_lengths = data[1].to(device)\n",
        "    \n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    preds = model(X).float()\n",
        "    loss = criterion(preds, y.long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    batch_loss = round(loss.item(), 2)\n",
        "\n",
        "    if i % 1000 == 0: #every 1000 batch\n",
        "      print(\"loss of the {}'th batch : {}\".format(i, batch_loss))\n",
        "  epoch_loss = round(epoch_loss, 2)\n",
        "  print(\"Epoch {}'th loss: {}\".format(epoch+1, epoch_loss))\n",
        "  print()\n",
        "  print(\"Evaluation ...\")\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    precision = 0\n",
        "    for (data, labels), _ in train_iterator:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      \n",
        "      outputs = model(X).float()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "\n",
        "    precision = round((100 * correct / total), 2)\n",
        "    print('Precision on the validation set: {}'.format(precision))\n",
        "  print()\n",
        "  #early_stopping\n",
        "  if early_stopping_param == LOSS:\n",
        "    if epoch_loss < best_early_stopping_param:\n",
        "      best_early_stopping_param = epoch_loss\n",
        "      patience = early_stopping_rate\n",
        "      save_model(model)\n",
        "    else:\n",
        "      patience -= 1\n",
        "  elif early_stopping_param == EVAL_PRECISION:\n",
        "    if precision > best_early_stopping_param:\n",
        "      best_early_stopping_aram = precision\n",
        "      patience = early_stopping_rate\n",
        "      save_model(model)\n",
        "    else:\n",
        "      patience -= 1\n",
        "  \n",
        "\n",
        "  print(\"Early stopping patience : {}\".format(patience))\n",
        "\n",
        "  if patience == 0:\n",
        "    print(\"Training stopped due to early stopping.\")\n",
        "    break\n",
        "\n",
        "  # Note that step should be called after validate()\n",
        "  scheduler.step(best_early_stopping_param)\n",
        "  print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training :\n",
            "Starting epoch 1\n",
            "loss of the 0'th batch : 1.61\n",
            "loss of the 1000'th batch : 1.53\n",
            "loss of the 2000'th batch : 1.44\n",
            "loss of the 3000'th batch : 1.46\n",
            "loss of the 4000'th batch : 1.53\n",
            "loss of the 5000'th batch : 1.67\n",
            "Epoch 1'th loss: 9257.07\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 39.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 2\n",
            "loss of the 0'th batch : 1.63\n",
            "loss of the 1000'th batch : 1.65\n",
            "loss of the 2000'th batch : 1.57\n",
            "loss of the 3000'th batch : 1.37\n",
            "loss of the 4000'th batch : 1.39\n",
            "loss of the 5000'th batch : 1.45\n",
            "Epoch 2'th loss: 8699.07\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 62.5\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 3\n",
            "loss of the 0'th batch : 1.39\n",
            "loss of the 1000'th batch : 1.4\n",
            "loss of the 2000'th batch : 1.51\n",
            "loss of the 3000'th batch : 1.46\n",
            "loss of the 4000'th batch : 1.46\n",
            "loss of the 5000'th batch : 1.37\n",
            "Epoch 3'th loss: 8410.35\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 59.38\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 4\n",
            "loss of the 0'th batch : 1.49\n",
            "loss of the 1000'th batch : 1.36\n",
            "loss of the 2000'th batch : 1.34\n",
            "loss of the 3000'th batch : 1.47\n",
            "loss of the 4000'th batch : 1.75\n",
            "loss of the 5000'th batch : 1.45\n",
            "Epoch 4'th loss: 8500.04\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 67.19\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 5\n",
            "loss of the 0'th batch : 1.45\n",
            "loss of the 1000'th batch : 1.37\n",
            "loss of the 2000'th batch : 1.31\n",
            "loss of the 3000'th batch : 1.41\n",
            "loss of the 4000'th batch : 1.32\n",
            "loss of the 5000'th batch : 1.36\n",
            "Epoch 5'th loss: 8034.42\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 64.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 6\n",
            "loss of the 0'th batch : 1.26\n",
            "loss of the 1000'th batch : 1.64\n",
            "loss of the 2000'th batch : 1.79\n",
            "loss of the 3000'th batch : 1.39\n",
            "loss of the 4000'th batch : 1.32\n",
            "loss of the 5000'th batch : 1.33\n",
            "Epoch 6'th loss: 8066.81\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 73.44\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 7\n",
            "loss of the 0'th batch : 1.31\n",
            "loss of the 1000'th batch : 1.32\n",
            "loss of the 2000'th batch : 1.34\n",
            "loss of the 3000'th batch : 1.38\n",
            "loss of the 4000'th batch : 1.27\n",
            "loss of the 5000'th batch : 1.43\n",
            "Epoch 7'th loss: 7867.51\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 37.5\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 8\n",
            "loss of the 0'th batch : 1.66\n",
            "loss of the 1000'th batch : 1.38\n",
            "loss of the 2000'th batch : 1.32\n",
            "loss of the 3000'th batch : 1.38\n",
            "loss of the 4000'th batch : 1.31\n",
            "loss of the 5000'th batch : 1.33\n",
            "Epoch 8'th loss: 7702.35\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 85.94\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 9\n",
            "loss of the 0'th batch : 1.26\n",
            "loss of the 1000'th batch : 1.28\n",
            "loss of the 2000'th batch : 1.37\n",
            "loss of the 3000'th batch : 1.22\n",
            "loss of the 4000'th batch : 1.25\n",
            "loss of the 5000'th batch : 1.36\n",
            "Epoch 9'th loss: 7360.32\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 96.88\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 10\n",
            "loss of the 0'th batch : 1.17\n",
            "loss of the 1000'th batch : 1.45\n",
            "loss of the 2000'th batch : 1.39\n",
            "loss of the 3000'th batch : 1.32\n",
            "loss of the 4000'th batch : 1.42\n",
            "loss of the 5000'th batch : 1.17\n",
            "Epoch 10'th loss: 7720.8\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 70.31\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 11\n",
            "loss of the 0'th batch : 1.28\n",
            "loss of the 1000'th batch : 1.23\n",
            "loss of the 2000'th batch : 1.32\n",
            "loss of the 3000'th batch : 1.16\n",
            "loss of the 4000'th batch : 1.17\n",
            "loss of the 5000'th batch : 1.33\n",
            "Epoch 11'th loss: 7362.78\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 92.19\n",
            "\n",
            "Early stopping patience : 3\n",
            "\n",
            "Starting epoch 12\n",
            "loss of the 0'th batch : 1.18\n",
            "loss of the 1000'th batch : 1.29\n",
            "loss of the 2000'th batch : 1.25\n",
            "loss of the 3000'th batch : 1.33\n",
            "loss of the 4000'th batch : 1.17\n",
            "loss of the 5000'th batch : 1.16\n",
            "Epoch 12'th loss: 7241.26\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 73.44\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 13\n",
            "loss of the 0'th batch : 1.46\n",
            "loss of the 1000'th batch : 1.29\n",
            "loss of the 2000'th batch : 1.22\n",
            "loss of the 3000'th batch : 1.41\n",
            "loss of the 4000'th batch : 1.32\n",
            "loss of the 5000'th batch : 1.15\n",
            "Epoch 13'th loss: 7209.39\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 71.88\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 14\n",
            "loss of the 0'th batch : 1.17\n",
            "loss of the 1000'th batch : 1.33\n",
            "loss of the 2000'th batch : 1.28\n",
            "loss of the 3000'th batch : 1.22\n",
            "loss of the 4000'th batch : 1.23\n",
            "loss of the 5000'th batch : 1.23\n",
            "Epoch 14'th loss: 7141.93\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 81.25\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 15\n",
            "loss of the 0'th batch : 1.23\n",
            "loss of the 1000'th batch : 1.22\n",
            "loss of the 2000'th batch : 1.19\n",
            "loss of the 3000'th batch : 1.25\n",
            "loss of the 4000'th batch : 1.28\n",
            "loss of the 5000'th batch : 1.23\n",
            "Epoch 15'th loss: 7150.18\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 78.12\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 16\n",
            "loss of the 0'th batch : 1.28\n",
            "loss of the 1000'th batch : 1.18\n",
            "loss of the 2000'th batch : 1.28\n",
            "loss of the 3000'th batch : 1.12\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.32\n",
            "Epoch 16'th loss: 7104.43\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 82.81\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 17\n",
            "loss of the 0'th batch : 1.18\n",
            "loss of the 1000'th batch : 1.22\n",
            "loss of the 2000'th batch : 1.18\n",
            "loss of the 3000'th batch : 1.17\n",
            "loss of the 4000'th batch : 1.22\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 17'th loss: 7075.32\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 85.94\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 18\n",
            "loss of the 0'th batch : 1.21\n",
            "loss of the 1000'th batch : 1.21\n",
            "loss of the 2000'th batch : 1.24\n",
            "loss of the 3000'th batch : 1.17\n",
            "loss of the 4000'th batch : 1.19\n",
            "loss of the 5000'th batch : 1.3\n",
            "Epoch 18'th loss: 7061.11\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 19\n",
            "loss of the 0'th batch : 1.15\n",
            "loss of the 1000'th batch : 1.16\n",
            "loss of the 2000'th batch : 1.18\n",
            "loss of the 3000'th batch : 1.19\n",
            "loss of the 4000'th batch : 1.2\n",
            "loss of the 5000'th batch : 1.17\n",
            "Epoch 19'th loss: 7044.79\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 20\n",
            "loss of the 0'th batch : 1.17\n",
            "loss of the 1000'th batch : 1.28\n",
            "loss of the 2000'th batch : 1.17\n",
            "loss of the 3000'th batch : 1.21\n",
            "loss of the 4000'th batch : 1.17\n",
            "loss of the 5000'th batch : 1.08\n",
            "Epoch 20'th loss: 6944.51\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 79.17\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 21\n",
            "loss of the 0'th batch : 1.11\n",
            "loss of the 1000'th batch : 1.18\n",
            "loss of the 2000'th batch : 1.14\n",
            "loss of the 3000'th batch : 1.18\n",
            "loss of the 4000'th batch : 1.18\n",
            "loss of the 5000'th batch : 1.21\n",
            "Epoch 21'th loss: 6832.38\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 22\n",
            "loss of the 0'th batch : 1.13\n",
            "loss of the 1000'th batch : 1.25\n",
            "loss of the 2000'th batch : 1.16\n",
            "loss of the 3000'th batch : 1.12\n",
            "loss of the 4000'th batch : 1.1\n",
            "loss of the 5000'th batch : 1.1\n",
            "Epoch 22'th loss: 6792.06\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 23\n",
            "loss of the 0'th batch : 1.23\n",
            "loss of the 1000'th batch : 1.14\n",
            "loss of the 2000'th batch : 1.22\n",
            "loss of the 3000'th batch : 1.11\n",
            "loss of the 4000'th batch : 1.18\n",
            "loss of the 5000'th batch : 1.11\n",
            "Epoch 23'th loss: 6769.94\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 95.31\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 24\n",
            "loss of the 0'th batch : 1.11\n",
            "loss of the 1000'th batch : 1.2\n",
            "loss of the 2000'th batch : 1.19\n",
            "loss of the 3000'th batch : 1.12\n",
            "loss of the 4000'th batch : 1.32\n",
            "loss of the 5000'th batch : 1.22\n",
            "Epoch 24'th loss: 6865.25\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 25\n",
            "loss of the 0'th batch : 1.2\n",
            "loss of the 1000'th batch : 1.23\n",
            "loss of the 2000'th batch : 1.15\n",
            "loss of the 3000'th batch : 1.21\n",
            "loss of the 4000'th batch : 1.17\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 25'th loss: 6846.71\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 90.62\n",
            "\n",
            "Early stopping patience : 3\n",
            "\n",
            "Starting epoch 26\n",
            "loss of the 0'th batch : 1.15\n",
            "loss of the 1000'th batch : 1.2\n",
            "loss of the 2000'th batch : 1.14\n",
            "loss of the 3000'th batch : 1.19\n",
            "loss of the 4000'th batch : 1.2\n",
            "loss of the 5000'th batch : 1.18\n",
            "Epoch 26'th loss: 6823.27\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 84.38\n",
            "\n",
            "Early stopping patience : 2\n",
            "Epoch    26: reducing learning rate of group 0 to 3.0000e-04.\n",
            "\n",
            "Starting epoch 27\n",
            "loss of the 0'th batch : 1.18\n",
            "loss of the 1000'th batch : 1.14\n",
            "loss of the 2000'th batch : 1.12\n",
            "loss of the 3000'th batch : 1.15\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.15\n",
            "Epoch 27'th loss: 6772.09\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 82.81\n",
            "\n",
            "Early stopping patience : 1\n",
            "\n",
            "Starting epoch 28\n",
            "loss of the 0'th batch : 1.17\n",
            "loss of the 1000'th batch : 1.16\n",
            "loss of the 2000'th batch : 1.09\n",
            "loss of the 3000'th batch : 1.33\n",
            "loss of the 4000'th batch : 1.18\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 28'th loss: 6760.79\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 87.5\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 29\n",
            "loss of the 0'th batch : 1.14\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.15\n",
            "loss of the 3000'th batch : 1.26\n",
            "loss of the 4000'th batch : 1.21\n",
            "loss of the 5000'th batch : 1.15\n",
            "Epoch 29'th loss: 6743.14\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 30\n",
            "loss of the 0'th batch : 1.08\n",
            "loss of the 1000'th batch : 1.16\n",
            "loss of the 2000'th batch : 1.21\n",
            "loss of the 3000'th batch : 1.16\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.17\n",
            "Epoch 30'th loss: 6733.54\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 93.75\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 31\n",
            "loss of the 0'th batch : 1.16\n",
            "loss of the 1000'th batch : 1.11\n",
            "loss of the 2000'th batch : 1.13\n",
            "loss of the 3000'th batch : 1.16\n",
            "loss of the 4000'th batch : 1.24\n",
            "loss of the 5000'th batch : 1.19\n",
            "Epoch 31'th loss: 6726.78\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 32\n",
            "loss of the 0'th batch : 1.17\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.12\n",
            "loss of the 3000'th batch : 1.11\n",
            "loss of the 4000'th batch : 1.16\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 32'th loss: 6721.41\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 33\n",
            "loss of the 0'th batch : 1.12\n",
            "loss of the 1000'th batch : 1.23\n",
            "loss of the 2000'th batch : 1.18\n",
            "loss of the 3000'th batch : 1.14\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.09\n",
            "Epoch 33'th loss: 6715.16\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 81.25\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 34\n",
            "loss of the 0'th batch : 1.11\n",
            "loss of the 1000'th batch : 1.17\n",
            "loss of the 2000'th batch : 1.17\n",
            "loss of the 3000'th batch : 1.13\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.13\n",
            "Epoch 34'th loss: 6710.65\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 35\n",
            "loss of the 0'th batch : 1.15\n",
            "loss of the 1000'th batch : 1.2\n",
            "loss of the 2000'th batch : 1.19\n",
            "loss of the 3000'th batch : 1.15\n",
            "loss of the 4000'th batch : 1.14\n",
            "loss of the 5000'th batch : 1.16\n",
            "Epoch 35'th loss: 6720.57\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 36\n",
            "loss of the 0'th batch : 1.18\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.2\n",
            "loss of the 3000'th batch : 1.12\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.11\n",
            "Epoch 36'th loss: 6711.07\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Early stopping patience : 3\n",
            "\n",
            "Starting epoch 37\n",
            "loss of the 0'th batch : 1.12\n",
            "loss of the 1000'th batch : 1.19\n",
            "loss of the 2000'th batch : 1.11\n",
            "loss of the 3000'th batch : 1.15\n",
            "loss of the 4000'th batch : 1.14\n",
            "loss of the 5000'th batch : 1.13\n",
            "Epoch 37'th loss: 6705.99\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 84.38\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 38\n",
            "loss of the 0'th batch : 1.19\n",
            "loss of the 1000'th batch : 1.11\n",
            "loss of the 2000'th batch : 1.2\n",
            "loss of the 3000'th batch : 1.09\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 38'th loss: 6702.8\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 92.19\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 39\n",
            "loss of the 0'th batch : 1.11\n",
            "loss of the 1000'th batch : 1.11\n",
            "loss of the 2000'th batch : 1.15\n",
            "loss of the 3000'th batch : 1.09\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.12\n",
            "Epoch 39'th loss: 6699.0\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 40\n",
            "loss of the 0'th batch : 1.14\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.12\n",
            "loss of the 3000'th batch : 1.17\n",
            "loss of the 4000'th batch : 1.08\n",
            "loss of the 5000'th batch : 1.18\n",
            "Epoch 40'th loss: 6697.21\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 93.75\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 41\n",
            "loss of the 0'th batch : 1.15\n",
            "loss of the 1000'th batch : 1.1\n",
            "loss of the 2000'th batch : 1.11\n",
            "loss of the 3000'th batch : 1.09\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.11\n",
            "Epoch 41'th loss: 6695.66\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 93.75\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 42\n",
            "loss of the 0'th batch : 1.16\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.08\n",
            "loss of the 3000'th batch : 1.18\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.17\n",
            "Epoch 42'th loss: 6695.8\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 43\n",
            "loss of the 0'th batch : 1.14\n",
            "loss of the 1000'th batch : 1.12\n",
            "loss of the 2000'th batch : 1.11\n",
            "loss of the 3000'th batch : 1.18\n",
            "loss of the 4000'th batch : 1.16\n",
            "loss of the 5000'th batch : 1.1\n",
            "Epoch 43'th loss: 6691.14\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 81.25\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 44\n",
            "loss of the 0'th batch : 1.14\n",
            "loss of the 1000'th batch : 1.09\n",
            "loss of the 2000'th batch : 1.18\n",
            "loss of the 3000'th batch : 1.17\n",
            "loss of the 4000'th batch : 1.15\n",
            "loss of the 5000'th batch : 1.26\n",
            "Epoch 44'th loss: 6689.08\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 45\n",
            "loss of the 0'th batch : 1.19\n",
            "loss of the 1000'th batch : 1.17\n",
            "loss of the 2000'th batch : 1.15\n",
            "loss of the 3000'th batch : 1.23\n",
            "loss of the 4000'th batch : 1.09\n",
            "loss of the 5000'th batch : 1.14\n",
            "Epoch 45'th loss: 6689.3\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 90.62\n",
            "\n",
            "Early stopping patience : 4\n",
            "\n",
            "Starting epoch 46\n",
            "loss of the 0'th batch : 1.09\n",
            "loss of the 1000'th batch : 1.07\n",
            "loss of the 2000'th batch : 1.18\n",
            "loss of the 3000'th batch : 1.11\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.1\n",
            "Epoch 46'th loss: 6690.43\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 85.94\n",
            "\n",
            "Early stopping patience : 3\n",
            "\n",
            "Starting epoch 47\n",
            "loss of the 0'th batch : 1.18\n",
            "loss of the 1000'th batch : 1.25\n",
            "loss of the 2000'th batch : 1.23\n",
            "loss of the 3000'th batch : 1.14\n",
            "loss of the 4000'th batch : 1.13\n",
            "loss of the 5000'th batch : 1.12\n",
            "Epoch 47'th loss: 6685.93\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 92.19\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 48\n",
            "loss of the 0'th batch : 1.14\n",
            "loss of the 1000'th batch : 1.11\n",
            "loss of the 2000'th batch : 1.11\n",
            "loss of the 3000'th batch : 1.17\n",
            "loss of the 4000'th batch : 1.12\n",
            "loss of the 5000'th batch : 1.18\n",
            "Epoch 48'th loss: 6683.51\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 87.5\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 49\n",
            "loss of the 0'th batch : 1.11\n",
            "loss of the 1000'th batch : 1.09\n",
            "loss of the 2000'th batch : 1.1\n",
            "loss of the 3000'th batch : 1.09\n",
            "loss of the 4000'th batch : 1.14\n",
            "loss of the 5000'th batch : 1.06\n",
            "Epoch 49'th loss: 6681.44\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 89.06\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n",
            "Starting epoch 50\n",
            "loss of the 0'th batch : 1.12\n",
            "loss of the 1000'th batch : 1.2\n",
            "loss of the 2000'th batch : 1.22\n",
            "loss of the 3000'th batch : 1.12\n",
            "loss of the 4000'th batch : 1.11\n",
            "loss of the 5000'th batch : 1.12\n",
            "Epoch 50'th loss: 6680.13\n",
            "\n",
            "Evaluation ...\n",
            "Precision on the validation set: 95.31\n",
            "\n",
            "Saving model\n",
            "Early stopping patience : 5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1V1DxHBVcJ7",
        "colab_type": "text"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-XlkQOWVdxq",
        "colab_type": "code",
        "outputId": "13afb20e-1017-47ee-dcf5-bff39c553cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = Net(vocab_size, emb_dim, hidden_state, nb_layers, nb_class, padding_idx,bidirectional).to(device)\n",
        "model.load_state_dict(torch.load(os.path.join(MODELS_DIR, MODEL_NAME)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAQaNL4fl9B",
        "colab_type": "code",
        "outputId": "8a8ca38b-e916-4ec7-eeb0-0c6fd4a2d5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_preds = torch.tensor([], dtype=torch.long).to(device) #used for ploting results\n",
        "all_gt = torch.tensor([], dtype=torch.long).to(device) #used for plotting results\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for (data, labels), _ in test_iterator:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device).long()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      predicted = predicted.long()\n",
        "      all_preds = torch.cat(\n",
        "              (all_preds, predicted)\n",
        "              ,dim=0\n",
        "          )\n",
        "      all_gt = torch.cat(\n",
        "              (all_gt, y)\n",
        "              ,dim=0\n",
        "          )\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "    \n",
        "precision = round((100 * correct / total), 2)\n",
        "print('Precision on the test set: {}'.format(precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision on the test set: 95.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL_2pO9GhPQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this code is taken from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwEk_adAhaMx",
        "colab_type": "code",
        "outputId": "40b99763-6499-49fb-fc38-0bfbc8d5722a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "cm = confusion_matrix(all_gt.cpu(), all_preds.cpu())\n",
        "plt.figure(figsize=(10,10))\n",
        "plot_confusion_matrix(cm, Y_prepocessing.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 0, 0,  ..., 1, 1, 3], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAALICAYAAACZ/POpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEx8JUmSNBD+P0JR+UJzoCBnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0ACZXr9v4oY",
        "colab_type": "text"
      },
      "source": [
        "We don't have enough of surprised data to make our model understand this sentiment. and we can clearly see that whanever our model is not predicting well, it's when the two emotions are correlated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H24SYcSAiTdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emotion(model, sentence):\n",
        "  \"\"\"\n",
        "  function that return the emotion of the sentence given in the parameter by the order of the weights\n",
        "  Args:\n",
        "    - model : model to use to predict\n",
        "    - sentence : sentence to predict its emotion\n",
        "  return:\n",
        "    - list of the emotion ordered by their weights\n",
        "    - list of the weights\n",
        "  \"\"\"\n",
        "  X = torch.Tensor([[X_prepocessing.vocab.stoi[word] for word in sentence.split(\" \")]]).to(device).long()\n",
        "  preds = model(X)\n",
        "  result = torch.argmax(preds, dim=-1)\n",
        "  return [Y_prepocessing.vocab.itos[p.item()] for p in preds[0].argsort(dim=-1, descending=True)], preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-_1woxcivuv",
        "colab_type": "code",
        "outputId": "e4f2a459-b752-46dd-bf86-769375c4cac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(get_emotion(model, \"i was happy but now i am furious\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['anger', 'love', 'joy', 'surprise', 'fear', 'sadness'], tensor([[3.9040e-03, 1.3445e-06, 9.8639e-01, 1.5221e-06, 9.6409e-03, 6.1463e-05]],\n",
            "       device='cuda:0', grad_fn=<SoftmaxBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}